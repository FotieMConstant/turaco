# Turaco

**Turaco-8B** is the first large language model (LLM) fine-tuned specifically to fluently speak native Pidgin English. Built upon Meta's LLAMA3.1-8B base model, Turaco empowers users across Africa to communicate seamlessly in Pidgin English, from Cameroon to Nigeria and beyond.

## Features

- Fluent in African Pidgin English (Cameroon, Nigeria, and other regions).
- Trained using curated datasets from sources like [Glosbe](https://glosbe.com/wes/en) and other Pidgin language resources across the web.
- Focused on natural, conversational responses in Pidgin English.

## Getting Started

<!-- ### Installation

1. Clone the repository:

```bash
git clone https://github.com/
``` -->

### Model Download

To download and use the fine-tuned Turaco model, you can visit the following link to Hugging Face:

[Download Turaco Model](https://huggingface.co/fotiecodes/Turaco-8B-v0.1)

### Training Notebook

If you're interested in understanding how the model was trained or want to fine-tune it further, you can check out the fine-tuning notebook on Google Colab:

[Fine-tuning Notebook](https://colab.research.google.com/drive/1AXj8RwXMVE4Bum4e0fyadvsktgTIUJfz?usp=sharing)

## Contributing

We welcome contributions from the community. Please refer to the `CONTRIBUTING.md` file for guidelines on how to get involved.

## License

This project is licensed under a custom license. Please see the `LICENSE.md` file for more information.
